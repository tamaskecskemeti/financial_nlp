{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Bseqc2QxcwxZqQr8ff88BlmvENf7NoyX",
      "authorship_tag": "ABX9TyOLw7ZZZvAsZEV9m0ZBr9eM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamaskecskemeti/financial_nlp/blob/main/nlp_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ6rG1F_dZZ_",
        "outputId": "a63056ad-6a14-4f8c-c949-b957f367aa69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: transformers==4.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.22.2)\n",
            "Requirement already satisfied: datasets==2.13.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval==1.2.2->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval==1.2.2->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2->-r requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2->-r requirements.txt (line 3)) (3.8.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2->-r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 1)) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2->-r requirements.txt (line 3)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.2->-r requirements.txt (line 3)) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# install required packages written in requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, set_seed, AutoTokenizer\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import itertools"
      ],
      "metadata": {
        "id": "WR2g2FVMeASy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "id": "UuUR6mQIlToV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function creator"
      ],
      "metadata": {
        "id": "6S0iKjm9tF7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_from_input(tokenizer, model, input_text):\n",
        "  input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "  out = model.generate(input_ids,\n",
        "                     max_new_tokens=50,\n",
        "                     num_beams=5,\n",
        "                     no_repeat_ngram_size=4,\n",
        "                     top_k=50,\n",
        "                     do_sample=True,\n",
        "                     top_p=0.9,\n",
        "                     temperature=1,\n",
        "                     early_stopping=True,\n",
        "                     pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  out_text = list(map(tokenizer.decode, out))[0]\n",
        "\n",
        "  return out_text"
      ],
      "metadata": {
        "id": "v6N8-cCOouBp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rouge scores for a reference/generated sentence pair\n",
        "# source google seq2seq source code.\n",
        "\n",
        "# supporting function\n",
        "def _split_into_words(sentences):\n",
        "  \"\"\"Splits multiple sentences into words and flattens the result\"\"\"\n",
        "  return list(itertools.chain(*[_.split(\" \") for _ in sentences]))\n",
        "\n",
        "# supporting function\n",
        "def _get_word_ngrams(n, sentences):\n",
        "  \"\"\"Calculates word n-grams for multiple sentences.\n",
        "  \"\"\"\n",
        "  assert len(sentences) > 0\n",
        "  assert n > 0\n",
        "\n",
        "  words = _split_into_words(sentences)\n",
        "  return _get_ngrams(n, words)\n",
        "\n",
        "# supporting function\n",
        "def _get_ngrams(n, text):\n",
        "  \"\"\"Calcualtes n-grams.\n",
        "  Args:\n",
        "    n: which n-grams to calculate\n",
        "    text: An array of tokens\n",
        "  Returns:\n",
        "    A set of n-grams\n",
        "  \"\"\"\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "def rouge_n(reference_sentences, evaluated_sentences, n=2):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentences: The sentences from the referene set\n",
        "    n: Size of ngram.  Defaults to 2.\n",
        "  Returns:\n",
        "    recall rouge score(float)\n",
        "  Raises:\n",
        "    ValueError: raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n",
        "  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n",
        "  reference_count = len(reference_ngrams)\n",
        "  evaluated_count = len(evaluated_ngrams)\n",
        "\n",
        "  # gets the overlapping ngrams between evaluated and reference\n",
        "  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
        "  overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "  # handle edge case. This isn't mathematically correct, but it's good enough\n",
        "  if evaluated_count == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = overlapping_count / evaluated_count\n",
        "\n",
        "  if reference_count == 0:\n",
        "    recall = 0.0\n",
        "  else:\n",
        "    recall = overlapping_count / reference_count\n",
        "\n",
        "  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
        "\n",
        "  # just returning recall count in rouge, useful for our purpose\n",
        "  return recall"
      ],
      "metadata": {
        "id": "sS7OpwlOqY2d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some text to test the model\n",
        "text_en = \"The Turing test, originally called the imitation game by Alan Turing in 1950 is a test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human.\""
      ],
      "metadata": {
        "id": "-YNOtV9arHNE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# English model"
      ],
      "metadata": {
        "id": "iNtGwxWItwgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_1_en = AutoTokenizer.from_pretrained(\"sberbank-ai/mGPT\")\n",
        "model_1_en = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/mGPT\")\n",
        "\n",
        "generated_text_1_en = generate_text_from_input(tokenizer_1_en, model_1_en, text_en)"
      ],
      "metadata": {
        "id": "sYgWTwf6pV9V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text_1_en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "gJkhPmPVtPtO",
        "outputId": "107e8d61-9cba-423a-ef6b-f52544511798"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Turing test, originally called the imitation game by Alan Turing in 1950 is a test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human. The Turing test was first published in 1951, and was used to test the Turing machine.\\nThe Turing test was originally developed by Alan Turing and published in 1951. It was originally intended to test Turing's ability to imitate human behavior. The test\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_2_en = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model_2_en = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "generated_text_2_en = generate_text_from_input(tokenizer_2_en, model_2_en, text_en)"
      ],
      "metadata": {
        "id": "auLo4MlArEkR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the reference text is used to evaluate the generated text\n",
        "ref_text_en = \"The Turing test, originally called the imitation game by Alan Turing in 1950 is a test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human. Turing proposed that a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses. The evaluator would be aware that one of the two partners in conversation was a machine, and all participants would be separated from one another. The conversation would be limited to a text-only channel, such as a computer keyboard and screen, so the result would not depend on the machine's ability to render words as speech. If the evaluator could not reliably tell the machine from the human, the machine would be said to have passed the test. The test results would not depend on the machine's ability to give correct answers to questions, only on how closely its answers resembled those a human would give. Since the Turing test is a test of indistinguishability in performance capacity, the verbal version generalizes naturally to all of human performance capacity, verbal as well as nonverbal (robotic).\""
      ],
      "metadata": {
        "id": "L5_mJY7ktoPs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_en, generated_text_1_en))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T0jtFgw-9ZY",
        "outputId": "1cf720c7-4ef1-487b-a1f2-49b66c809e19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5365853658536586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_en, generated_text_2_en))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7pvusaSFd_v",
        "outputId": "0768a00d-14df-4cee-d121-f558bec388b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5528455284552846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hungarian model"
      ],
      "metadata": {
        "id": "05dOnZW2NHWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some text in hungarian to test the model\n",
        "text_hu = \"A Turing-teszt, amelyet eredetileg Alan Turing 1950-ben imitációs játéknak nevezett el, egy olyan teszt, amely azt vizsgálja, hogy egy gép képes-e az emberi viselkedéssel egyenértékű vagy attól megkülönböztethetetlen intelligens viselkedést tanúsítani.\"\n"
      ],
      "metadata": {
        "id": "p7_Sc7BVrpJ6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_1_hu = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model_1_hu = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "generated_text_1_hu = generate_text_from_input(tokenizer_1_hu, model_1_hu, text_hu)"
      ],
      "metadata": {
        "id": "MnQyOhikfpUq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_2_hu = AutoTokenizer.from_pretrained(\"NYTK/PULI-GPT-2\")\n",
        "model_2_hu = GPT2LMHeadModel.from_pretrained(\"NYTK/PULI-GPT-2\")\n",
        "\n",
        "generated_text_2_hu = generate_text_from_input(tokenizer_2_hu, model_2_hu, text_hu)"
      ],
      "metadata": {
        "id": "QTHSQs2Sr53q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the reference text is used to evaluate the generated text\n",
        "ref_text_hu = \"A Turing-teszt, amelyet eredetileg Alan Turing 1950-ben imitációs játéknak nevezett el, egy olyan teszt, amely azt vizsgálja, hogy egy gép képes-e az emberi viselkedéssel egyenértékű vagy attól megkülönböztethetetlen intelligens viselkedést tanúsítani. Turing azt javasolta, hogy egy emberi értékelő értékelje az ember és egy emberhez hasonló válaszok generálására tervezett gép közötti természetes nyelvű beszélgetéseket. Az értékelő tisztában lenne azzal, hogy a két beszélgetőpartner közül az egyik egy gép, és a résztvevők el lennének választva egymástól. A beszélgetés kizárólag szöveges csatornára korlátozódna, például számítógépes billentyűzetre és képernyőre, így az eredmény nem függne attól, hogy a gép képes-e a szavakat beszédként megjeleníteni. Ha az értékelő nem tudná megbízhatóan megkülönböztetni a gépet az embertől, akkor a gép átmenne a teszten. A teszt eredménye nem függne attól, hogy a gép képes-e helyes válaszokat adni a kérdésekre, csak attól, hogy a válaszai mennyire hasonlítanak az emberi válaszokhoz. Mivel a Turing-teszt a teljesítőképesség megkülönböztethetetlenségének tesztje, a verbális változat természetesen általánosítható az emberi teljesítőképesség egészére, a verbális és a nem verbális (robotikus) teljesítőképességre egyaránt.\""
      ],
      "metadata": {
        "id": "5gcijuhJt5YE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_hu, generated_text_1_hu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gazEI81KA6QS",
        "outputId": "09ecec4d-a4dd-450e-c5b2-8ce0659016ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5636942675159236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_hu, generated_text_2_hu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfgE3W0vEazT",
        "outputId": "4f666a78-e34a-455f-d235-d2b9adac0c95"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5445859872611465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune models"
      ],
      "metadata": {
        "id": "T5TFNXLXuFgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO load data from file (/data/train_data.csv)"
      ],
      "metadata": {
        "id": "_RHJXC0yuHev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "  dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def load_data_collator(tokenizer):\n",
        "  data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "    )\n",
        "  return data_collator\n",
        "\n",
        "\n",
        "def train(input_path,\n",
        "          model_name,\n",
        "          output_path,\n",
        "          per_device_train_batch_size,\n",
        "          num_train_epochs,\n",
        "          save_steps):\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  train_dataset = load_dataset(input_path, tokenizer)\n",
        "  data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "  tokenizer.save_pretrained(output_path)\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "  model.save_pretrained(output_path)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "          output_dir=output_path,\n",
        "          overwrite_output_dir=False,\n",
        "          per_device_train_batch_size=per_device_train_batch_size,\n",
        "          num_train_epochs=num_train_epochs,\n",
        "      )\n",
        "\n",
        "  trainer = Trainer(\n",
        "          model=model,\n",
        "          args=training_args,\n",
        "          data_collator=data_collator,\n",
        "          train_dataset=train_dataset,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  trainer.save_model()"
      ],
      "metadata": {
        "id": "4Pb-MtUF3P3A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path_en = \"/data/en/train_data.csv\"\n",
        "output_path_en = \"/data/en/result\"\n",
        "model_name_en = \"gpt2\"\n",
        "\n",
        "input_path_hu = \"/data/hu/train_data.csv\"\n",
        "output_path_hu = \"/data/hu/result\"\n",
        "model_name_hu = \"NYTK/PULI-GPT-2\"\n",
        "per_device_train_batch_size = 6\n",
        "num_train_epochs = 256\n",
        "save_steps = 250"
      ],
      "metadata": {
        "id": "n8YiY68FOQs7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    input_path=input_path_en,\n",
        "    model_name=model_name_en,\n",
        "    output_dir=output_path_en,\n",
        "    overwrite_output_dir=False,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ],
      "metadata": {
        "id": "FcSOWzx3Ownw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    input_path=input_path_hu,\n",
        "    model_name=model_name_hu,\n",
        "    output_dir=output_path_hu,\n",
        "    overwrite_output_dir=False,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ],
      "metadata": {
        "id": "DYWjPrFavH5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_en = \"Test data\""
      ],
      "metadata": {
        "id": "twJTk0xTx9uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_trained_en = AutoTokenizer.from_pretrained(output_path_en)\n",
        "model_trained_en = GPT2LMHeadModel.from_pretrained(output_path_en)\n",
        "\n",
        "generated_text_en = generate_text_from_input(tokenizer_trained_en, model_trained_en, text_en)"
      ],
      "metadata": {
        "id": "I2ejQ-NNx26J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_hu = \"Teszt adat\""
      ],
      "metadata": {
        "id": "-ud5y2xyPU46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_trained_hu = AutoTokenizer.from_pretrained(output_path_hu)\n",
        "model_trained_hu = GPT2LMHeadModel.from_pretrained(output_path_hu)\n",
        "\n",
        "generated_text_hu = generate_text_from_input(tokenizer_trained_hu, model_trained_hu, text_hu)"
      ],
      "metadata": {
        "id": "uISXw4kwxjKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_text_en = \"Test reference data\""
      ],
      "metadata": {
        "id": "Vs9ucQj7yPWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_en, generated_text_en))"
      ],
      "metadata": {
        "id": "mHz2pz91QRfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_text_hu = \"Teszt referencia adat\""
      ],
      "metadata": {
        "id": "vX89ejpzybRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the rouge value can be between 0 and 1. The higher value is better\n",
        "print(rouge_n(ref_text_hu, generated_text_hu))"
      ],
      "metadata": {
        "id": "gP0gCivDyYm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}